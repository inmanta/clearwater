"""
    This module models clearwater software components

    :copyright: 2017 Inmanta NV
    :contact: code@inmanta.com
"""
import apt
import clearwater::state
import clearwater::openstack
import dns
import exec
import ip
import ip::services
import logging
import param

versions = {
    "127": "http://repo.cw-ngv.com/archive/repo127/",
    "128": "http://repo.cw-ngv.com/stable/"
}

upgrade_order = ["vellum", "dime", "homer", "sprout", "bono", "ellis"]

entity VersionUpgrade:
    """
        This entity is used for all components and services that are upgradable. It sets the current version and a version to
        upgrade to.
    """
    string version
    string upgrade_version
    string name
end

entity ClearWater extends VersionUpgrade:
    """
        The clearwater service.
    """
    string public_domain
    string private_domain
    bool create_dns_records
    ip::ip[] dns_servers

    number base_number=6505550000
    number number_cnt=1000
end

implement ClearWater using selectVersion

implementation selectVersion for ClearWater:
    self.name = "clearwater"
    self.version = clearwater::select_service_version(self)
    self.fsm = clearwater::state::ServiceState()
end

entity Host extends ip::Host:
end
implement Host using std::hostDefaults, privateIP

Host.private_ip [1] -- ip::IP
Host.public_ip [0:1] -- ip::IP

implementation privateIP for Host:
    self.private_ip = ip::IP(v4=self.ip)
end

# Required services
Sprout.clearwater [1] -- ClearWater.sprout [1:]
Dime.clearwater   [1] -- ClearWater.dime [1:]
Vellum.clearwater [1] -- ClearWater.vellum [3:]

# Optional services
Homer.clearwater  [1] -- ClearWater.homer [0:]
Ellis.clearwater  [1] -- ClearWater.ellis [0:1]
Bono.clearwater   [1] -- ClearWater.bono [0:]

# All hosts running clearwater services
Host.clearwater   [1] -- ClearWater.hosts [0:]

ClearWater.public_zone [0:1] -- dns::Zone
ClearWater.private_zone [0:1] -- dns::Zone

entity ClearwaterService extends ip::services::Server, VersionUpgrade:
    """
        A clearwater service component
    """
    string instance_name
    bool create_dns_records
    string vnf_name
    number vnf_instance
    bool decommission
    bool upgrade
    string repo
end

ClearWater.services [0:] -- ClearwaterService

# Use this package as synchronisation point
ClearwaterService.cw_mgmt [1] -- std::Package
ClearwaterService.local_cfg [1] -- std::File

entity Homer extends ClearwaterService:
    """
        XDMS

        Homer is a standard XDMS used to store MMTEL service settings documents for each user of the system. Documents are created,
        read, updated and deleted using a standard XCAP interface. As with Homestead, the Homer nodes use Vellum as the data store
        for all long lived data.
    """
    string vnf_name="homer"
end

entity Ellis extends ClearwaterService:
    """
        Ellis is a sample provisioning portal providing self sign-up, password management, line management and control of MMTEL
        service settings. It is not intended to be a part of production Clearwater deployments (it is not easy to horizontally
        scale because of the MySQL underpinnings for one thing) but to make the system easy to use out of the box.
    """
    string vnf_name="ellis"
end

entity Bono extends ClearwaterService:
    """
        Edge Proxy

        The Bono nodes form a horizontally scalable SIP edge proxy providing both a SIP IMS Gm
        compliant interface and a WebRTC interface to clients. Client connections are load balanced across the nodes.
        The Bono node provides the anchor point for the client’s connection to the Clearwater system, including
        support for various NAT traversal mechanisms. A client is therefore anchored to a particular Bono node for
        the duration of its registration, but can move to another Bono node if the connection or client fails.

        Clients can connect to Bono using SIP/UDP or SIP/TCP. Bono supports any WebRTC client that performs call
        setup signaling using SIP over WebSocket.

        Alternatively, Clearwater can be deployed with a third party P-CSCF or Session Border Controller implementing P-CSCF.
        In this case Bono nodes are not required.
    """
    string vnf_name="bono"
end

entity Sprout extends ClearwaterService:
    """
        SIP Router

        The Sprout nodes act as a horizontally scalable, combined SIP registrar and authoritative routing proxy, and handle
        client authentication and the ISC interface to application servers. The Sprout nodes also contain the in-built MMTEL
        application server. SIP transactions are load balanced across the Sprout cluster, so there is no long-lived association
        between a client and a particular Sprout node. Sprout does not store any long-lived data itself and instead uses -
        web services interfaces to Homestead and Homer to retrieve HSS configuration such as authentication data/user profiles
        and MMTEL service settings - APIs to Vellum for storing subscriber registration data and for running timers.

        Sprout is where the bulk of the I-CSCF and S-CSCF function resides, with the remainder provided by Dime
        (and backed by the long-lived data stores on Vellum).
    """
    bool memento=true
    string vnf_name="sprout"
end

entity Dime extends ClearwaterService:
    """
        Dime nodes run Clearwater’s Homestead and Ralf components.

        - Homestead (HSS Cache) provides a web services interface to Sprout for retrieving authentication credentials and user
          profile information. It can either master the data (in which case it exposes a web services provisioning interface)
          or can pull the data from an IMS compliant HSS over the Cx interface. The Homestead nodes themselves are stateless -
          the mastered / cached subscriber data is all stored on Vellum (via Cassandra’s Thrift interface).

          In the IMS architecture, the HSS mirror function is considered to be part of the I-CSCF and S-CSCF components, so in
          Clearwater I-CSCF and S-CSCF function is implemented with a combination of Sprout and Dime clusters.

        - Ralf (CTF) provides an HTTP API that both Bono and Sprout can use to report billable events that should be passed to the
          CDF (Charging Data Function) over the Rf billing interface. Ralf is stateless, using Vellum to maintain the long lived session
          state and run the timers necessary to enable it to conform to the Rf protocol.
    """
    string vnf_name="dime"
end

entity Vellum extends ClearwaterService:
    """
        State store

        As described above, Vellum is used to maintain all long-lived state in the dedployment. It does this by running a number
        of cloud optimized, distributed storage clusters.

        - Cassandra. Cassandra is used by Homestead to store authentication credentials and profile information, and is used by Homer
          to store MMTEL service settings. Vellum exposes Cassandra’s Thrift API.
        - etcd. etcd is used by Vellum itself to share clustering information between Vellum nodes and by other nodes in the deployment
          for shared configuration. - Chronos. Chronos is a distributed, redundant, reliable timer service developed by Clearwater.
          It is used by Sprout and Ralf nodes to enable timers to be run (e.g. for SIP Registration expiry) without pinning operations
          to a specific node (one node can set the timer and another act on it when it pops). Chronos is accessed via an HTTP API.
        - Memcached / Astaire. Vellum also runs a Memcached cluster fronted by Astaire. Astaire is a service developed by Clearwater
          that enabled more rapid scale up and scale down of memcached clusters. This cluster is used by Sprout and Ralf for storing
          registration and session state.
    """
    string vnf_name="vellum"
end

implementation clearwaterService for ClearwaterService:
    # model "bookkeeping"
    self.clearwater.services = self
    self.instance_name = "{{vnf_name}}-{{vnf_instance}}"
    self.name = "{{vnf_name}}_{{vnf_instance}}"

    # versioning
    self.version = clearwater::get_current_version(self)
    self.upgrade_version = clearwater::get_upgrade_version(self)

    # generic for all clearwater components
    apt::Repository(host=host, name="clearwater", release="binary/", repo="", base_url=self.repo)

    cwdir = std::DefaultDirectory(host=host, path="/etc/clearwater")
    f_c = std::ConfigFile(host=host, path="/etc/clearwater/local_config", requires=cwdir,
                          content=std::template("clearwater/local_config.template"))
    self.local_cfg = f_c

    # This package already starts stuff so make sure that the config file is already there.
    p_mgmt = std::Package(host=host, name="clearwater-management", state="installed", requires=f_c)
    self.cw_mgmt = p_mgmt

    self.clearwater.hosts = self.host

    # Sometimes the etc state dir is not created
    std::Directory(host=host, path="/var/lib/clearwater-etcd", owner="clearwater-etcd", group="clearwater-etcd", mode="770",
                   requires=p_mgmt)

    # Only update these when clearwater packages have been installed
    f_1 = std::ConfigFile(host=host, path="/etc/dnsmasq.d/resolv.conf", content=std::template("clearwater/dnsmasq.template"),
                          reload=true, requires=p_mgmt)
    f_2 = std::ConfigFile(host=host, path="/etc/default/dnsmasq", content=std::template("clearwater/dnsmasq.default"),
                          reload=true, requires=p_mgmt)
    std::Service(host=host, name="dnsmasq", state="running", requires=[f_1, f_2], onboot=true)

    # add snmp alarms
    std::Package(host=host, name="clearwater-snmp-alarm-agent", state="installed", requires=self.cw_mgmt)

    # Add statemachine
    clearwater::state::VNFCState(service=self)

    # current version
    std::ConfigFile(host=self.host, path="/etc/clearwater-version", content=self.version)
end

implementation decommission for ClearwaterService:
    # Implementation for all components added when the service is decommissioned
end

implementation upgrade for ClearwaterService:
    script = std::File(host=self.host, path="/usr/bin/upgrade.sh", mode=755, owner="root", group="root",
                       content=std::source("clearwater/upgrade.sh"))
    exec::Run(host=self.host, command="/usr/bin/upgrade.sh", provides=self.fsm, send_event=true, timeout=1800)
end

implementation chronos for ClearwaterService:
    std::DefaultDirectory(host=host, path="/etc/chronos")
    f_c = std::ConfigFile(host=host, path="/etc/chronos/chronos.conf", content=std::template("clearwater/chronos.tmpl"))
end

## Homer
implementation homer for Homer:
    std::Package(host=host, name="homer", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)

    logging::LogDir(host=host, name="homer", path="/var/log/homer", matches="homer_(?P<date>\d+)T(?P<time>\d+)Z.txt",
                    priority=["date", "time"], type="clearwater")
end

implementation homerDNS for Homer:
    dns::A(zone=clearwater.private_zone, resource="homer", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="{{ host.name }}.", ipaddress=host.private_ip.v4)
end

implementation decommissionHomer for Homer:
    unmon = exec::Run(host=self.host, command="/usr/bin/monit unmonitor -g homer")
    q = exec::Run(host=self.host, command="/usr/sbin/service homer stop", requires=unmon, provides=self.fsm, send_event=true)
end

implement Homer using homer, clearwaterService
implement Homer using homerDNS when clearwater.create_dns_records and create_dns_records
implement Homer using decommission, decommissionHomer when decommission

## Ellis
implementation ellis for Ellis:
    p = std::Package(host=host, name="ellis", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)

    logging::LogDir(host=host, name="ellis", path="/var/log/ellis", matches="ellis_(?P<date>\d+)T(?P<time>\d+)Z.txt",
                    priority=["date", "time"], type="clearwater")

    # generate secrets
    signup_key=std::generate_password("cw_signup_key")
    turn_workaround=std::generate_password("cw_turn_workaround")
    ellis_api_key=std::generate_password("cw_ellis_api_key")
    ellis_cookie_key=std::generate_password("cw_ellis_cookie_key")

    # report config information to dashboard
    param::report("ellis", "http://{{ host.public_ip.v4 }}/")
    param::report("signup key", signup_key)

    # setup shared config
    f = std::ConfigFile(host=host, path="/etc/clearwater/shared_config",
                        content=std::template("clearwater/shared_config.j2"),
                        requires=p, reload=true)
    ccs = std::ConfigFile(host=host, path="/usr/bin/cw_config_setup", content=std::source("clearwater/config_setup.sh"),
                          mode=755)
    config = exec::Run(host=host, command="/usr/bin/cw_config_setup", requires=[f, ccs])

    # provision telephone numbers (run this everytime, it is idempotent
    exec::Run(host=host, command="/usr/share/clearwater/ellis/env/bin/python create_numbers.py --start {{ clearwater.base_number }} --count {{ clearwater.number_cnt }}",
              cwd="/usr/share/clearwater/ellis/src/metaswitch/ellis/tools/", requires=[config], skip_on_fail=true)
end

implementation ellisDNS for Ellis:
    dns::A(zone=clearwater.private_zone, resource="ellis-1", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="ellis", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.public_zone, resource="ellis", ipaddress=host.public_ip.v4)
end

implement Ellis using ellis, clearwaterService
implement Ellis using ellisDNS when clearwater.create_dns_records and create_dns_records

## Bono
implementation bono for Bono:
    std::Package(host=host, name="bono", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
    std::Package(host=host, name="clearwater-snmpd", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
    std::Package(host=host, name="restund", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)

    logging::LogDir(host=host, name="bono", path="/var/log/bono", matches="bono_(?P<date>\d+)T(?P<time>\d+)Z.txt",
                    priority=["date", "time"], type="clearwater")
end

implementation bonoDNS for Bono:
    dns::A(zone=clearwater.private_zone, resource="{{ host.name }}.", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="bono", ipaddress=host.private_ip.v4)
    dns::ResourceRecord(zone=clearwater.private_zone, resource="_sip._tcp", record_type="SRV", value="0 0 5060 {{host.name}}.")

    dns::A(zone=clearwater.public_zone, resource="@", ipaddress=host.public_ip.v4)
    public_name = std::replace(host.name, clearwater.private_domain, clearwater.public_domain)
    dns::A(zone=clearwater.public_zone, resource="{{ public_name }}.", ipaddress=host.public_ip.v4)

    dns::ResourceRecord(zone=clearwater.public_zone, resource="_sip._tcp", record_type="SRV", value="0 0 5060 {{public_name}}.")
    dns::ResourceRecord(zone=clearwater.public_zone, resource="_sip._udp", record_type="SRV", value="0 0 5060 {{public_name}}.")
end

implementation decommissionBono for Bono:
    unmon = exec::Run(host=self.host, command="/usr/bin/monit unmonitor -g bono")
    q = exec::Run(host=self.host, command="/usr/sbin/service bono quiesce", requires=unmon, provides=self.fsm, send_event=true)
end

implement Bono using bono, clearwaterService
implement Bono using bonoDNS when clearwater.create_dns_records and create_dns_records
implement Bono using decommission, decommissionBono when decommission

## Sprout
implementation sprout for Sprout:
    std::Package(host=host, name="sprout", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
    std::Package(host=host, name="clearwater-snmpd", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)

    logging::LogDir(host=host, name="sprout", path="/var/log/sprout", matches="sprout_(?P<date>\d+)T(?P<time>\d+)Z.txt",
                    priority=["date", "time"], type="clearwater")
end

implementation sproutMemento for Sprout:
    std::Package(host=host, name="memento-as", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
    std::Package(host=host, name="memento-nginx", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
end

implementation sproutDNS for Sprout:
    dns::A(zone=clearwater.private_zone, resource="{{ host.name }}.", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="sprout", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="scscf.sprout", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="icscf.sprout", ipaddress=host.private_ip.v4)

    dns::ResourceRecord(zone=clearwater.private_zone, resource="_sip._tcp.sprout", record_type="SRV", value="0 0 5054 {{host.name}}.")
    dns::ResourceRecord(zone=clearwater.private_zone, resource="_sip._tcp.scscf.sprout", record_type="SRV", value="0 0 5054 {{host.name}}.")
    dns::ResourceRecord(zone=clearwater.private_zone, resource="_sip._tcp.icscf.sprout", record_type="SRV", value="0 0 5052 {{host.name}}.")
end

implementation decommissionSprout for Sprout:
    unmon = exec::Run(host=self.host, command="/usr/bin/monit unmonitor -g sprout")
    q = exec::Run(host=self.host, command="/usr/sbin/service sprout quiesce", requires=unmon, provides=self.fsm, send_event=true)
end

implement Sprout using decommission, decommissionSprout when decommission
implement Sprout using sproutMemento when memento
implement Sprout using sprout, clearwaterService, chronos
implement Sprout using sproutDNS when clearwater.create_dns_records and create_dns_records

## Dime
implementation dime for Dime:
    std::Package(host=host, name="dime", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
    std::Package(host=host, name="clearwater-prov-tools", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
    std::Package(host=host, name="clearwater-snmpd", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
end

implementation dimeDNS for Dime:
    dns::A(zone=clearwater.private_zone, resource="{{ host.name }}.", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="hs", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="ralf", ipaddress=host.private_ip.v4)
end

implementation decommissionDime for Dime:
    unmon = exec::Run(host=self.host, command="/usr/bin/monit unmonitor -g homestead && /usr/bin/monit unmonitor -g homestead-prov && /usr/bin/monit unmonitor -g ralf")
    q = exec::Run(host=self.host, command="/usr/sbin/service homestead stop && /usr/sbin/service homestead-prov stop && /usr/sbin/service ralf stop",
                  requires=unmon, provides=self.fsm, send_event=true)
end

implement Dime using decommission, decommissionDime when decommission
implement Dime using dime, clearwaterService
implement Dime using dimeDNS when clearwater.create_dns_records and create_dns_records

## Vellum
implementation vellum for Vellum:
    std::Package(host=host, name="vellum", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
    std::Package(host=host, name="clearwater-snmpd", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
    std::Package(host=host, name="clearwater-snmp-handler-astaire", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
end

implementation vellumMemento for Vellum:
    std::Package(host=host, name="memento-cassandra", state="installed", provides=self.cw_mgmt, requires=self.local_cfg)
end

implementation vellumDNS for Vellum:
    dns::A(zone=clearwater.private_zone, resource="{{ host.name }}.", ipaddress=host.private_ip.v4)
    dns::A(zone=clearwater.private_zone, resource="vellum", ipaddress=host.private_ip.v4)
end

implementation decommissionVellum for Vellum:
    unmon_ccm = exec::Run(host=self.host, command="/usr/bin/monit unmonitor -g clearwater_cluster_manager")
    unmon_cm = exec::Run(host=self.host, command="/usr/bin/monit unmonitor -g clearwater_config_manager", requires=unmon_ccm)
    unmon_qm = exec::Run(host=self.host, command="/usr/bin/monit unmonitor -g clearwater_queue_manager", requires=unmon_cm)
    unmon_etcd = exec::Run(host=self.host, command="/usr/bin/monit unmonitor -g etcd", requires=unmon_qm)
    q = exec::Run(host=self.host, command="/usr/sbin/service clearwater-etcd decommission",
                  requires=unmon_etcd, provides=self.fsm, send_event=true)
end

implement Vellum using decommission, decommissionVellum when decommission
implement Vellum using vellum, vellumMemento, clearwaterService
implement Vellum using vellumDNS when clearwater.create_dns_records and create_dns_records
implement Vellum using upgrade when upgrade

## Managed DNS
# By default each hosts adds its hostname to the private zone
implementation clearwaterDNS for ClearWater:
    dns::ResourceRecord(zone=private_zone, resource="bono", record_type="NAPTR", value="1 1 \"S\" \"SIP+D2T\" \"\" _sip._tcp")
    dns::ResourceRecord(zone=private_zone, resource="bono", record_type="NAPTR", value="1 2 \"S\" \"SIP+D2U\" \"\" _sip._udp")

    dns::ResourceRecord(zone=private_zone, resource="sprout", record_type="NAPTR", value="1 1 \"S\" \"SIP+D2T\" \"\" _sip._tcp.sprout")
    dns::ResourceRecord(zone=private_zone, resource="scscf.sprout", record_type="NAPTR", value="1 1 \"S\" \"SIP+D2T\" \"\" _sip._tcp.scscf.sprout")
    dns::ResourceRecord(zone=private_zone, resource="icscf.sprout", record_type="NAPTR", value="1 1 \"S\" \"SIP+D2T\" \"\" _sip._tcp.icscf.sprout")

    dns::ResourceRecord(zone=public_zone, resource="@", record_type="NAPTR", value="1 1 \"S\" \"SIP+D2T\" \"\" _sip._tcp")
    dns::ResourceRecord(zone=public_zone, resource="@", record_type="NAPTR", value="1 2 \"S\" \"SIP+D2U\" \"\" _sip._udp")
end

implement ClearWater using clearwaterDNS when create_dns_records

implementation hostRecords for Host:
    dns::A(zone=clearwater.private_zone, resource="{{name}}.", ipaddress=ip)
end
implement Host using hostRecords when clearwater.create_dns_records
